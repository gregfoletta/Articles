---
title: TCP Analysis
author: ''
date: '2024-04-07'
slug: []
categories: []
tags: []
images: []
---

```{r include=FALSE}
library(tidyverse)
library(cmdstanr)
library(tidybayes)
library(gt)
library(here)

knitr::opts_chunk$set(
    comment = ''
)
```

I currently work for a [network & security vendor](https://fortinet.com) whos main product is a firewall. When sizing firewalls there's a two main things to consider: the throughput, and the conncurrent connections. Sizing based on throughput is relatively easy: what's the aggregate bandwidth connected to the device. But concurrent connections is a little harder. Imagine a head office with 200 people, how many concurrent connections would you expect? Also, what's our certainty about this?

In this article we're going to try and answer this question by taking Bayesian perspective. We'll do this by using real packet capture data from my laptop, and using this as an input to a STAN program. THe STAN program estimate the parameters for the probability distributions for the connections per second, and the connection duration. We'll then simulate connections by pulling values from these probability distributions.

The result is an idea of the probable concurrent connections that we can use to size our firewall.

# Caveats Firsts

Let's be up-front in where the flaws are with this. The first is that it's predicated on everyone else's behaviour looking like mine. For an office scenario I don't think this is too far fetched: my data was taken during a normal work day, so it's got Microsoft Teams, web-browsing, Outlook; the standard worker fare. But we need to be aware that not everyones traffic profile looks like this.

The second is that in real life, concurrent connections rise and fall like the tide based on people's behaviour.


# Traffic Data

I used `tshark` to capture my wlan0 interface over the course of the day, piping this in to `jq` to filter out the fields I didn't need to reduce the size. The commandline looked like this:

```sh
tshark -Tjson -J 'frame eth ip tcp udp' -iwlan0 | jq --stream --from-file pcap_stream_filter.jq
```

```json
[
    {
      "frame.time": "Apr 17, 2024 10:16:19.373894967 AEST",
      "frame.time_epoch": "1713312979.373894967",
      "frame.time_delta": "0.000000000",
      "frame.time_relative": "0.000000000",
      "frame.number": "1",
      "frame.protocols": "eth:ethertype:ip:tcp:tls",
      "eth.src": "e0:23:ff:65:52:61",
      "eth.dst": "6c:94:66:78:d4:e4",
      "ip.src": "10.50.9.66",
      "ip.dst": "10.50.3.2",
      "udp.stream": null,
      "tcp.srcport": "3389",
      "tcp.dstport": "56708",
      "tcp.stream": "0",
      "tcp.flags_tree": {
        "tcp.flags.res": "0",
        "tcp.flags.ns": "0",
        "tcp.flags.cwr": "0",
        "tcp.flags.ecn": "0",
        "tcp.flags.urg": "0",
        "tcp.flags.ack": "1",
        "tcp.flags.push": "1",
        "tcp.flags.reset": "0",
        "tcp.flags.syn": "0",
        "tcp.flags.fin": "0",
        "tcp.flags.str": "·······AP···"
      },
    },
    ...
]
```

You can take a look at the [*pcap_stream_filter.jq* here](pcap_stream_filter.jq). The data is loaded into R and we do some wrangling:


```{r load, include=FALSE}
pcap <- read_rds('20240417_pcap.Rdata')
```

After a bit of wrangling, including filtering for just TCP and UDP, unnesting the TCP flags tree, and converting the time to a POSIXct object, the data is in a form where we can actually use it:

```{r clean, include=FALSE}
pcap_reduced <-
    pcap |>
    separate(
        frame.protocols,
        into = paste0('frame.protocols.', c('l1', 'l2', 'l3', 'l4', 'l5', 'remain')), sep = ':',
        extra = 'merge',
        remove = FALSE 
    ) |> 
    # Filter out TCP and UDP
    filter(!is.na(udp.stream) | !is.na(tcp.stream)) |>
    unnest(tcp.flags_tree) |> 
    mutate(
        time = as.double(frame.time_epoch),
        id = as.double(frame.number)
    ) |> 
    mutate(time  = as.POSIXct(time)) |> 
    select(c(time, frame.time_relative, id, eth.src, eth.dst, tcp.stream, udp.stream, tcp.srcport, tcp.dstport, tcp.flags.syn, tcp.flags.ack, tcp.flags.fin, tcp.flags.reset, flags_string = tcp.flags.str)) |>
    mutate(across(c( starts_with('tcp.'), udp.stream ), as.integer)) |>
    mutate(frame.time_relative = as.double(frame.time_relative))


# Split out TCP and UDP
tcp_segments <- pcap_reduced |> filter(!is.na(tcp.stream)) |> arrange(time)
udp_datagrams <- pcap_reduced |> filter(!is.na(udp.stream)) |> select(-starts_with('tcp')) |> filter(!str_detect(eth.dst, '^(33:33|01:00|ff:ff)')) |>  arrange(time)
```


```{r echo=FALSE}
# Show table
pcap_reduced |>
    slice_head(n = 50) |>
    gt()
```

# Connections Per Second

Determining the connections per second is relatively easy. For TCP we group by each TCP stream, filter out any streams for which we haven't seen a SYN (began before we started the packet capture) or where only see SYNs (connection never fully established). We can then count the number of SYNs that ocurred each second, then merge in the full range of time values so it's continues across our range:

```{r tcp_cps}
# TCP connections are based on the the first SYN seen
tcp_connections <-
    tcp_segments |>
    # Conver back from POSIXct to integer
    mutate(time = as.integer(time)) |> 
    group_by(tcp.stream) |> 
    # Filter out any where by haven't seen the initial SYN
    filter(any(tcp.flags.syn == 1 & tcp.flags.ack == 0)) |>
    # Filter out any where we've ONLY seen the initial SYN
    filter(!all(tcp.flags.syn == 1)) |> 
    ungroup() |> 
    # Group by each second and count the number of SYNs
    group_by(time) |>
    summarise(cps = sum(tcp.flags.syn)) |> 
    # Fill in any missing gaps in our time columns
    full_join(
        tibble(
            time = as.integer( first(tcp_segments$time):last(tcp_segments$time) ),
        ),
        by = 'time'
    ) |>
    arrange(time) |>
    # The merged in rows are implicitly 0 
    mutate(cps = replace_na(cps, 0))
```

UDP has no concept of a conneciton, so we group by UDP stream, filter for the first datagram in each stream that has more than one datagram:

```{r cps}
# UDP connections based simply on first datagram per stream seen
udp_connections <-
    udp_datagrams |>
    mutate(time = as.integer(time)) |> 
    group_by(udp.stream) |>
    # Filter out the first datagram in streams with more than one datagram
    filter(row_number() == 1 & n() > 1) |>
    ungroup() |>
    count(time, name = 'cps') |> 
    full_join(
        tibble(
            time = as.integer( first(udp_datagrams$time):last(udp_datagrams$time) ),
        ),
        by = 'time'
    ) |> 
    arrange(time) |> 
    mutate(cps = replace_na(cps, 0))

# Merge TCP and UDP back together
connections_per_second <- 
    bind_rows(tcp = tcp_connections, udp = udp_connections, .id = 'protocol')
```

We merge these two dataframes together and can 

```{r echo=FALSE}
connections_per_second |>
    ggplot() +
    geom_histogram(aes(cps, after_stat(density), fill = protocol), binwidth = 1) +
    scale_x_binned(limits = c(0, 10)) +
    labs(
        x = 'CPS',
        y = 'Density',
        title = 'TCP and UDP - Connections per Second Histogram',
        subtitle = 'Limited between 0 and 10',
        fill = 'Protocol'
    )
```

# Connection Length

We now need to calculate the session length for each TCP and UDP stream. While the initial start of the TCP stream is well defined, the end is a bit messier. They don't all end with a nice FIN/FIN-ACK, and even if they do often you'll see an RST come through 20 to 30 seconds later. Here's a breakdown of the TCP flags for the last segment in each of the TCP streams:

```{r echo=FALSE}
tcp_segments |>
    group_by(tcp.stream) |>
    slice_tail(n = 1) |> 
    ungroup() |> 
    count(flags_string, sort = TRUE) |>
    gt() |>
    cols_label(flags_string = "TCP Flags", n = 'Count')
```

We'll keep it simple an take the duration to be the time between the first and last segment seen in the packet capture:

```{r tcp_session_duration}
tcp_session_duration <-
    tcp_segments |>
    group_by(tcp.stream) |>
    # Filter out any where by haven't seen the initial SYN
    filter(any(tcp.flags.syn == 1 & tcp.flags.ack == 0)) |>
    # Filter out any where we've ONLY seen the initial SYN
    filter(!all(tcp.flags.syn == 1)) |>
    # Remove streams with no RST or FIN
    filter(!any(tcp.flags.fin) | !any(tcp.flags.reset)) |> 
    # Calculate the duration
    summarise(duration = last(frame.time_relative) - first(frame.time_relative)) |>
    rename(stream = tcp.stream)
```

We'll do the same for UDP, then merge the two dataframes together:

```{r udp_session_duration}
# UDP session length
udp_session_duration <-
    udp_datagrams |>
    group_by(udp.stream) |>
    filter(n() != 1) |>
    summarise(duration = last(frame.time_relative) - first(frame.time_relative)) |>
    rename(stream = udp.stream)

session_duration <- 
    bind_rows(tcp = tcp_session_duration, udp = udp_session_duration, .id = 'protocol') 
```



```{r session_histogram}
session_duration |> 
    ggplot() +
    geom_histogram(aes(duration, after_stat(density), fill = protocol), bins = 256) +
    scale_x_continuous(limits = c(10, 130)) +
    labs(
        title = 'TCP and UDP - Session Duration Density',
        subtitle = 'X-Axis Range Limited (0, 130)',
        x = 'Duration (Seconds)',
        y = 'Density',
        fill = 'Protocol'
    )
```




# Modelling

```
data {
  int<lower = 0> n_cps, n_duration;
  array[n_cps] int cps;
  vector[n_duration] duration;
}
parameters { 
    //cps neg_binomial() parameters
    real<lower = 0> nb_alpha;
    real<lower = 0> nb_beta;
    
    //duration gamma() parameteres 
    real<lower = 0> g_alpha;
    real<lower = 0> g_beta;
}
model {
    // negative binomial priors
    nb_alpha ~ exponential(.5);
    nb_beta ~ exponential(.5);
    
    //gamma priors
    g_alpha ~ exponential(.5);
    g_beta ~ exponential(.5);
    
    //model
    cps ~ neg_binomial(nb_alpha, nb_beta);
    duration ~ gamma(g_alpha, g_beta);
}

generated quantities {
    array[1000] int cps_sim;
    array[1000] real duration_sim;
    
    for (n in 1:1000) {
        cps_sim[n] = neg_binomial_rng(nb_alpha, nb_beta);
        duration_sim[n] = gamma_rng(g_alpha, g_beta);
    }
}
```


```{r stan_cps_model, message=FALSE, warning=FALSE, include=FALSE}
tcp_model <- cmdstan_model('cps_and_duration_model.stan')

tcp_fit <- tcp_model$sample(
    data = compose_data(
        cps = select(connections_per_second, cps),
        duration = select(session_duration, duration)
    ),
    chains = 4,
    parallel_chains = 4
)
```


```{r assess_chains}
tcp_fit |> 
    gather_draws(nb_alpha, nb_beta, g_alpha, g_beta) |>
    recover_types() |> 
    ggplot() +
    geom_line(aes(.iteration, .value, colour = as_factor(.chain)), alpha = .8) +
    facet_grid(vars(.variable), scales = 'free_y')

tcp_fit |> 
    gather_draws(nb_alpha, nb_beta, g_alpha, g_beta) |>
    recover_types() |> 
    ggplot() +
    geom_histogram(aes(.value, fill = as.factor(.chain)), bins = 100) +
    facet_wrap(vars(.variable), scales = 'free')
```
```{r echo=FALSE, message=FALSE, warning=FALSE}
tcp_fit |>
    recover_types() |>
    spread_draws(cps_sim[i]) |>
    ungroup() |> 
    select(cps = cps_sim) |> 
    bind_rows(simulated = _, real = tcp_connections, .id = 'set') |> 
    ggplot() +
    geom_histogram(aes(cps, after_stat(density), fill = set), binwidth = 1, position = position_dodge()) +
    scale_x_binned(limits = c(0, 10)) +
    facet_wrap(~set) +
    labs(
        title = 'Connections per Second - Real vs. Simulated Datasets',
        subtitle = 'Density Histogram',
        x = 'Connections per Second',
        y = 'Density',
        fill = 'Data Set'
    )
```
```{r}
tcp_fit |>
    recover_types() |>
    spread_draws(duration_sim[i]) |>
    transmute(duration = duration_sim) |> 
    bind_rows(real = _, simulated = session_duration, .id = 'set') |> 
    ggplot() +
    geom_histogram(aes(duration, after_stat(density), fill = set), binwidth = 1) +
    scale_x_continuous(limits = c(-1, 25)) +
    facet_wrap(~set) +
    labs(
        title = 'TCP and UDP - Session Duration - Real vs. Simulated Datasets',
        subtitle = 'Density Histogram',
        x = 'Duration (Seconds)',
        y = 'Density',
        fill = 'Data Set'
    )
```

# Simulating Users

```{r}
posterior_distros <-
    tcp_fit |>
    recover_types() |>
    spread_draws(cps_sim[i], duration_sim[i])
```

```{r}
# This function takes a vector of durations and returns a vector of
# connections initiated at each point int time.
connections <- function(duration) {
    n <- length(duration)
    concurrent <- rep(0, n) 
    
    for (x in 1:n) {
        duration_len <- length(duration[[x]])
        # duration[x] is a list of doubles
        if(duration_len == 0) { next }
        
        for (y in 1:length(duration_len)) {
            # Increase the connection at the current time
            concurrent[x] <- concurrent[x] + 1
            
            # Decrease the connections after the duration
            #session_duration <- ceiling(duration[[x]])
            session_duration <- ceiling(duration[[x]][y])
            
            session_end <- x + session_duration
           
            # Don't decrement if it's past the end of our session window 
            if (session_end > n) {
                next
            }
            
            concurrent[session_end] <- concurrent[session_end] - 1
        }
    }
    
    concurrent
}
```

```{r real_concurrent}
# What's our 'real' concurrent connections per second?
real_concurrent_connections <-
    tcp_segments |>
    arrange(time) |> 
    mutate(time = as.integer(time)) |> 
    group_by(tcp.stream) |> 
    # Filter out any where by haven't seen the initial SYN
    filter(any(tcp.flags.syn == 1 & tcp.flags.ack == 0)) |>
    # Filter out any where we've ONLY seen the initial SYN
    filter(!all(tcp.flags.syn == 1)) |>
    mutate(
        start_end = case_when(
            row_number() == 1 ~ 1,
            row_number() == n() ~ -1,
            .default = 0
        )
    ) |>
    ungroup() |> 
    select(time, tcp.stream, start_end) |> 
    full_join(
        tibble(
            time = as.integer( first(pcap_reduced$time):last(pcap_reduced$time) ),
        ),
        by = 'time'
    ) |>
    arrange(time) |>
    mutate(start_end = replace_na(start_end, 0)) |> 
    group_by(time) |>
    summarise(connections_per_second = sum(start_end)) |>
    mutate(concurrent_connections = cumsum(connections_per_second)) |>
    select(time, concurrent_connections) |>
    mutate(time = (time - first(time) + 1))
```

```{r}
simulated_concurrent_connections <-
    expand_grid(
       time = 1:last(real_concurrent_connections$time),
       user = 1,
    ) |>
    mutate(
        cps = sample(posterior_distros$cps_sim, size = n(), replace = TRUE),
        duration = map(cps, ~{ sample(posterior_distros$duration_sim, size = .x, replace = TRUE) })
    ) |> 
    group_by(time) |>
    summarise(duration = list(unlist(duration)) ) |>  
    mutate(
        connections = connections(duration),
        concurrent_connections = cumsum(connections)
    ) |>
    select(time, concurrent_connections)

real_distro_drawn_connections <-
    expand_grid(
       time = 1:last(real_concurrent_connections$time),
       user = 1,
    ) |>
    mutate(
        cps = sample(tcp_connections$cps, size = n(), replace = TRUE),
        duration = map(cps, ~{ sample(tcp_session_duration$duration, size = .x, replace = TRUE) })
    ) |> 
    group_by(time) |>
    summarise(duration = list(unlist(duration)) ) |>  
    mutate(
        connections = connections(duration),
        concurrent_connections = cumsum(connections)
    ) |>
    select(time, concurrent_connections)
```


```{r}
connection_datasets <-
    bind_rows(
        real_concurrent_connections,
        simulated_concurrent_connections,
        real_distro_drawn_connections,
        .id = 'dataset'
    )

connection_datasets |> 
    mutate(set  = case_when(dataset == 1 ~ 'real', dataset == 2 ~ 'simulated_synthetic', dataset == 3 ~ 'simulated_real')) |>
    ggplot() +
    geom_point(aes(time, concurrent_connections, colour = set), size = .1, alpha = .5)

connection_datasets |> 
    mutate(set  = case_when(dataset == 1 ~ 'real', dataset == 2 ~ 'simulated_synthetic', dataset == 3 ~ 'simulated_real')) |>
    ggplot() +
    geom_histogram(aes(concurrent_connections, after_stat(density), group = set, fill = set), binwidth = 1, alpha = .5) +
    facet_grid(~set)
```



```{r}
map(c(1:10), ~{ expand_grid(users = .x, user = 1:.x, time = 1:(60 * 60 * 3)) }) |> 
    bind_rows() |>
    group_by(users) |>
    mutate(
        cps = sample(posterior_distros$cps_sim, size = n(), replace = TRUE),
        duration = map(cps, ~{ sample(posterior_distros$duration_sim, size = .x, replace = TRUE) })
    ) |>
    group_by(users, time) |> 
    summarise(duration = list(unlist(duration)), .groups = 'drop_last') |>
    mutate(
        connections = connections(duration),
        concurrent_connections = cumsum(connections)
    ) |>
    ggplot() +
    geom_histogram(aes(concurrent_connections, fill = as.factor(users), group = as.factor(users)), binwidth = 1, alpha = .7)
    #geom_boxplot(aes(users, concurrent_connections, group = users))
     
    
```

