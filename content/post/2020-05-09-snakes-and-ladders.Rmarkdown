---
title: Simulating Snakes and Ladders
author: Greg Foletta
date: '2020-05-05'
slug: snakes-and-ladders
categories: [R]
description: 'Simulating Snakes and Ladders with R'
always_allow_html: yes
---

```{r include=FALSE}
# Switch devices to allow for transparency..
knitr::opts_chunk$set(dev.args = list(png = list(type = "cairo")))
```


For the past couple of months my family and I - like most people - have been in isolation thanks to the coronavirus. My eldest son is 5 years old and is really into games and puzzles at moment, so these have been a key tool in reducing the boredom of lockdown. 

The board game he has really gotten into is 'snakes and ladders'. While sitting on the floor and playing a game for the umpteenth time, I started to wonder about some of the game's statistical properties. That's normal right?

In this article I want to try and answer two questions about these statistical properties. The first is:

> For my son's board, what is the average amount of dice rolls it takes to finish a game?

And the second is:

> What is the average amount of dice rolls it takes to finish a game for a generalised board?


# Defining the Board

This is the board we play on - it's large sheet of plastic, hence the crinkles:

![Our Snakes and Ladders Board](/post/snakes_and_ladders/board.jpg)

We'll represent this board (and other boards) as a vector with one element per 'spot' on the board. Each element holds the value of the shift that occurs when you land on it: negative for snakes, positive for ladders, or zero for neither.

The vector below is a representation of my son's board. I've let R do the calculations for me, entering values as *destination - source* for ladders and *source - destinaton* for snakes.

```{r}
our_board = c(
    38-1, 0, 0, 14-4, 0, 0, 0, 0, 31-9, 0,
    0, 0, 0, 0, 0, 6-16, 0, 0, 0, 0,
    42-21, 0, 0, 0, 0, 0, 0, 84-28, 0, 0,
    0, 0, 0, 0, 0, 44-36, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 26-47, 0, 11-49, 0,
    67-51, 0, 0, 0, 0, 53-56, 0, 0, 0, 0,
    0, 19-62, 0, 60-64, 0, 0, 0, 0, 0, 0,
    91-71, 0, 0, 0, 0, 0, 0, 0, 0, 100-80,
    0, 0, 0, 0, 0, 0, 24-87, 0, 0, 0,
    0, 0, 73-93, 0, 75-95, 0, 0, 78-98, 0, 0
)
```

# Playing the Game

We have a data structure that represents the board, now we need an algorithm that represents the game.

The `snl_game()` function takes a vector defining a board, and a finish type, and runs through a single player game until the game is complete, returning the number of rolls it took to finish the game.

The finish type specfies one of the two different ways a game can be finished. My son and I play an 'over' finish type, where any dice roll that takes you over the board length results in a win.

The other finish is the 'exact' type, where you need to land exactly on the board length + 1 to win. If you go over, you remain in your current place.
    
```{r message=FALSE}
library(tidyverse)
library(magrittr)
library(glue)
library(knitr)
library(kableExtra)
```

```{r}
snl_game <- function(board, finish = 'exact') {
    if (!finish %in% c('exact', 'over')) {
        stop("Argument 'finish' must be either 'exact' or 'over")
    }
    # We sart on 0, which is off the board. First space is 1
    pos <- 0
    # We finish one past the end of the board
    fin_pos <- length(board) + 1
    # roll counter
    rolls <- 0
    
    while (rolls <- rolls + 1) {
        # Roll the dice
        roll <- sample(1:6, 1)
        # Update the position
        next_pos <- pos + roll
        
        # Two types of finish:
        # a) We need an exact roll to win
        # b) We need any roll to win
        if (next_pos > fin_pos) { 
            if (finish == 'exact')  { next }
            else                    { return(rolls) }
        }
        
        # Did we win?
        if (next_pos == fin_pos) { return(rolls) }
        
        # Did we somehow move off the board in the negative direction?
        if (next_pos < 1) {
            warning(glue("Went into negative board position: {next_pos}"))
            return(NA_integer_)
        }
        
        # Take into account any snakes/ladders  
        pos <- next_pos + board[next_pos]
    }
}
```    


# Answering the Specific Question

Now that we have a board and a game, let's answer the specifuc queston about the average number of rolls to win on my son's board. Using my new favourite function `crossing()`, we simulate 200,000 games times for each of the finish types and calculate the mean number of rolls. We visualise this as a histogram:

```{r my_board_simulation}
# Simulate 200,000 games of each finish type 
our_board_sim <- 
    crossing(finish_type = c('exact', 'over'), n = 1:200000) %>% 
    mutate(rolls = map_dbl(finish_type, ~snl_game(our_board, finish = .x)))

# Summarise the results
our_board_summary <-
    our_board_sim %>% 
    group_by(finish_type) %>% 
    summarise(
        min = min(rolls),
        max = max(rolls),
        mean = mean(rolls),
        quantile_95 = quantile(rolls, .95),
        quantile_5 = quantile(rolls, .05)
    )

# Plot the histograms
our_board_sim %>% 
    ggplot() +
    geom_histogram(aes(rolls), binwidth = 1) +
    geom_vline(
        aes(xintercept = mean), 
        linetype = 'dashed', 
        colour = 'red', 
        our_board_summary
    ) +
    geom_label(aes(label = mean, x = mean, y = 0), our_board_summary) +
    facet_wrap(~finish_type, scales = 'free') +
    labs(
        x = 'Number of Dice Rolls',
        y = 'Number of Games',
        title = 'Snakes and Ladders - Dice Roll Histogram'
    )

our_board_summary %>% 
    kable() %>%
    kable_styling()
```

So we can see that it takes on average `r dplyr::filter(our_board_summary, finish_type == 'exact')[['mean']]` rolls to finish an 'exact' game type, and `r dplyr::filter(our_board_summary, finish_type == 'over')[['mean']]` rolls to finish an 'over' game type.

For the 'over' finish type that my son and I play, I estimate a dice roll and move to take around 10 seconds. Our games should on average take around`r ceiling((dplyr::filter(our_board_summary, finish_type == 'exact')[['mean']] * 2 * 10) / 60)`  minutes, with 95% of games finishing in less than `r ceiling(dplyr::filter(our_board_summary, finish_type == 'over')[['quantile_95']] * 2 * 10 / 60)` minutes.

# Answering the General Question

We've answered the specific question, but can we generalise this to any board? 

There are two random elements that we need to generate: which spots on the board will have a snake or a ladder, and the shift value for each of these spots.

For the latter we use the `spot_alloc()` function below. It takes a board 

The first step is to define the the shift - either forwards or backwards - of a single spot. This is done with the `spot_alloc()` function. The shift is taken from a normal distribution (truncated to an integer) and `min()`/`max()` clamped so that we don't shift ourselves off the bottom or the top of the board.

```{r}
spot_alloc <- function(spot, board_size, mean) {
    # Integer portion of a random normal variable
    r <- floor(rnorm(1, mean, board_size / 3))
   
    # Bound the snake or ladder by the bottom
    # and top of the board
    max(-(spot -1), min(board_size - spot, r))
}
```

The `snl_board()` generates a board, taking a board size, a proportion of the board that will be snakes and ladders, and a desired mean.

```{r}
snl_board <- function(board_size, proportion, mean) {
    # Allocate the board
    board <- rep(0, board_size)
   
    # Which spots will on the board will be snakes or ladders?
    spots <- trunc(runif(proportion * board_size, 1, board_size))
        
    # Assign to these spots either a snake or a ladder
    board[spots] <- map_dbl(spots, ~spot_alloc(.x, board_size, mean))
    
    return(board)
}
```

Due to the clamping, the mean we speciify in our argument to `snl_board()` doesn't have a purely linear relationship to the evential mean of the entire board. We can see below that it actually resembles a logistic function.

```{r}
crossing(n = 1:10, mean = seq(-200, 200, 3)) %>%
    mutate(board_mean = map_dbl(mean, ~mean(snl_board(100, .19, .x)))) %>% 
    ggplot() +
    geom_point(aes(mean, board_mean)) +
    labs(
        x = 'Specified Mean',
        y = 'Actual Mean',
        title = 'Specified Mean versus Actual Board Mean'
    )
```

We've got a board and a game, let's play some snakes and ladders. We'll simulate 500 games of each finish type for mean values between 0 and 50, generating a unique board for each simulation.
    
```{r}
set.seed(1)
general_snl_sim <-
    crossing(
        n = 1:500,
        mean = -2:50,
        finish_type = c('exact', 'over')
    ) %>% 
    mutate(
        board = map(mean, ~snl_board(100, .19, .x)),
        board_mean = map_dbl(board, ~mean(.x)),
        rolls = map2_dbl(board, finish_type, ~snl_game(.x, .y))
    )




general_snl_sim %>%
    ggplot() +
    geom_point(aes(board_mean, rolls, colour = finish_type), alpha = .1) +
    facet_wrap(~finish_type) +
    theme(legend.position = 'none') +
    labs(
        x = 'Board Mean',
        y = 'Number of Dice Rolls',
        title = 'Simulated Snakes and Ladders',
        subtitle = 'Mean of the Board vs. Number of Dice Rolls'
    )
```

# Modeling

We'll keep it simple and apply an ordinary least squares to each of the finish types separately.

```{r}
library(broom)

ols_models <-
general_snl_sim %>%
    group_by(finish_type) %>% 
    do(model = lm(rolls ~ board_mean, data = .) )


general_snl_sim %>%
    ggplot() +
    geom_point(aes(board_mean, rolls, colour = finish_type), alpha = .1) +
    geom_smooth(aes(board_mean, rolls), method = 'lm', formula = 'y ~ x', ) +
    facet_wrap(~finish_type) +
    theme(legend.position = 'none') +
    labs(
        x = 'Board Mean',
        y = 'Dice Rolls',
        title = 'Number of Dice Rolls vs Board Mean',
        subtitle = 'Split by Finish Type with OLS Best Fit'
    )
```

From this we can see that the intercepts, representing a board mean of 0, are `r round(dplyr::filter(tidy(ols_models, model), (finish_type == 'exact' & term == '(Intercept)'))[['estimate']], 1)` rolls for the exact finish type, and `r round(dplyr::filter(tidy(ols_models, model), (finish_type == 'over' & term == '(Intercept)'))[['estimate']], 1)` rolls for the over finish type.

In both of the finish types, the number of rolls required to finsh the game changes by `round(dplyr::filter(tidy(ols_models, model), (finish_type == 'over' & term == 'board_mean'))[['estimate']], 1)` - the negative specifying a decrease - for every increase of the board mean by one.

```{r}
ols_models %>% 
    tidy(model) %>% 
    kable() %>% 
    kable_styling()
```

How well does the least squares model the number of roles in terms of the mean of the board? The $R^2$ value tells us that it explains around a fifth to a quarter of the variance. On first glance that seems low, however it's probably reasonable given the randomness of the dice rolls and the snakes and ladders, and may be close to an upper bound on the variance that can be explained.

```{r}
ols_models %>% 
    glance(model) %>% 
    select(finish_type, r.squared) %>% 
    kable() %>% 
    kable_styling()
```
The next step is to perform some diagnostics on these models. The first thing to look at is a graph of the residuals versus the response variable. There are two things that stand out: 

```{r}
ols_models %>% 
    augment(model) %>% 
    ggplot() +
    geom_point(aes(.fitted, .resid, colour = finish_type), alpha = .1) +
    geom_smooth(aes(.fitted, .resid), method = 'loess') +
    facet_wrap(~finish_type) +
    labs(
        x = 'Fitted Value',
        y = 'Residuals',
        title = 'Residual Diagnostic Plot'
    )
```

## Non-Linearity

The first is that between the fitted values of 0 and about 30 rolls, we don't see a discernable pattern in the residual plot. In this space this use of a linear model is reasonable. However as we get above 30 rolls we start to see a curve, indicating that our linear model starts to break down.


## Homoscedasticity

The second thing to notice is the variance of the residuals increasing as the fitted values increase, appearing as a funnel shape in the plot. This implies that our residuals are **heteroscedastic**, whereas one of the assumptions of a linear regression is that the residuals are **homoscedastic**.

Breaking this assumption doesn't affect our estimated coefficients, but it does affect the bias of the standard errors, meaning our confidence intervals are inaccurate.

# Conclusion

At the outet of this article I wanted to answer two questions: what is the mean number of rolls it takes to finish a snakes and ladders game on a specific board, and what is the mean number of rolls to finish a game on a general board.

In the specific instance we simulated a large number of games on the specific board. Using this data we were able to determine the mean rolls, as well and lower 5% and upper 95% bounds. 

In the general instance we again simulated a large number of games on boards with different means. We it an ordinary least squares model to the data, but saw two issues: some non-linearity of the data in certain ranges of the independent variable, and heteroscedacticity of the residuals. The next steps in this instance would be to consider transforming the data, or trying different models.


