---
title: Poor Man's Wind Tunnel
author: ''
date: '2021-12-24'
slug: 
categories: []
tags: []
images: []
---

```{r include=FALSE}
library(tidyverse)
library(broom)
library(lubridate)
library(xml2)
library(cowplot)
```

One of my passtimes is to ride (and occasionally race) track bikes. These are the bikes you'll see 
I raced bikes as a junior, then came back to it in my mid thirties. One of the big contrasts has been the low barrier to entry for technology. When I was young everyone had bike computer that showed you your speed, but that was it. Now you've got speed, location via GPS, cadence, heart rate, and power. Looking and graphs and visualising the data is interesting, but I've been wanting to try and do more with it.

This article is split into two sections:

1. In the first section we will take cycling data that I've generated in a controlled manner, extract it from XML and transform it into a tidy, rectangular data frame. The goal is to show how elegance of R and how easy it performs manipulations like this.
1. In the second section we will use the data to create a "poor person's wind tunnel", determining how efficient different positions on the bike are in terms of watts saved. 


# Data Acquisition

Let's first talk about how the experimental set up and how the data was captured. I used a track bike (which has a single fixed gear) and rode it around the [Coburg velodrome](https://www.google.com/maps/@-37.7297305,144.9553304,147m/data=!3m1!1e3) which is a 250m outdoor track. A sensor (Wahoo speed) on the hub of the wheel collected speed data, my pedals (PowerTap P1) collected power and cadence, and a strap around my chest collected my heart rate.

Data was gathered while in two different positions on the bike[^1]. The first we will call on the 'tops', looked like this:
[^1]: Images courtesy of [bikegremlin.com](http://bikegremlin.com)

```{r, echo=FALSE, out.width="10%", fig.cap="Tops of the handlebars"}
knitr::include_graphics("tops.jpg")
```

The second which we will call the 'drops', looked like this:

```{r, echo=FALSE, out.width="10%", fig.cap="Tops of the handlebars"}
knitr::include_graphics("drops.jpg")
```

For each position the pace was slowly increasing from 10km/h to to 50km/h, in 8-10km/h increments. For each increment level, the pace was held as close as possible to constant for two laps, increasing to three laps for higher speeds in order to get enough samples.

There are two main external elements which affect our data generation process: wind, and the fact that the Coburg velodrome is not completely flat. However because we are moving around and oval, some noise will be added but none of the data should be biased. This noise will simply increase our uncertainty about our model's parameters.

# Transforming the Data

The data is downloaded in TCX (Training Center XML) format. While good for us that it's in a standard structured format, it's not quite in the rectangular tidy data structure that we need for our analysis. Our first step is to extract and transform it into this format. The XML is structured as a single *activity* with one or more *laps*. Each *lap* has *trackpoints* which contain a timestamp and the other data (speed, power, heartrate, etc) that's been ollected. A trackpoint is taken every one second.

Here's an example of the XML from the root to the a trackpoint. Only one lap and one trackpoint is shown.

```xml
<TrainingCenterDatabase>
    <Activities>
        <Activity>
            <Lap>
                <Track>
                    <Trackpoint>
                        <Time>2022-01-16T00:00:41Z</Time>
                        <DistanceMeters>1.48</DistanceMeters>
                        <HeartRateBpm>
                         <Value>105</Value>
                        </HearthRateBpm>
                        <Cadence>32</Cadence>
                        <Extensions>
                         <TPX>
                          <Speed>3.19</Speed>
                          <Watts>56</Watts>
                         </TPX>
                        </Extensions>
                    </Trackpoint>
                    <!-- Multiple trackpoints (1 second sample) --> 
                </Track>
            </Lap>
            <!-- Multiple laps (generated manually) -->
        </Activity>
    </Activities>
</TrainingCenterDatabase>
```

In what I think is a great example of the elegance and power of R, the following code takes our TCX file and uses XPath to extract out the fields we need, turning it into a tidy data frame.

```{r}
cycle_data <-
    read_xml('cycle_data.tcx') %>%
    xml_ns_strip() %>%
    xml_find_all('.//Trackpoint[Extensions]') %>%
    {
        tibble(
            time = xml_find_first(., './Time') %>% xml_text() %>% ymd_hms(),
            speed = xml_find_first(., './Extensions/TPX/Speed') %>% xml_double(),
            power = xml_find_first(., './Extensions/TPX/Watts') %>% xml_integer(),
            bpm = xml_find_first(., './HeartRateBpm/Value') %>% xml_integer(),
            cadence = xml_find_first(., './Cadence') %>% xml_integer(),
            lap = xml_find_num(
                .,
                'count(./parent::Track/parent::Lap/preceding-sibling::Lap)'
            ),
        )
    }

print(cycle_data)
```

I think it's worth going through each line:

1. The TCX file is read in as as an *xml_document*
1. The TCX is namespaced, but as we're only working with this file we strip the namespace to make our XPath shorter.
1. Using the `.//Trackpoint[Extensions]` XPath We find all trackpoint nodes that have a child extensions node. We can't just find all of the trackpoints as there seems to be a quirk where the first trackpoint has a timestamp but no other data.
1. We then construct a data frame (a tibble) by finding and extracting the text from our data nodes (speed, power, etc) from each of the trackpoints. The pipe to tibble is enclosed in braces to stop the left-hand side from automatically being placed as the first argument. 
1. To determine which lap the trackpoint is part of we find it's grandparent lap node, and then count how many preceding lap siblings it has. So the first lap has 0 preceding siblings, the second lap has 1, etc.

And that's it! with less than 20 lines of code we've been able to transform our XML into a tidy, rectangular data format ready for visualisation and analysis. Speaking of visualisation, let's take a look at a few different aspects of the data to get a general feel for it. First off is the power output over time with each lap coloured separately. Laps one and three contain the data that we will be using in our model.

```{r echo=FALSE}
cycle_data %>% 
    ggplot() +
    geom_line(aes(time, power, color = as.factor(lap)), size = .4) +
    labs(
        title = 'Track Cycling - Power over Time',
        subtitle = 'Laps differentiated by colour',
        x = 'Time',
        y = 'Power (Watts)',
        colour = 'Lap'
    )
```

As the the data was generated on a track bike which has only a single gear, the speed and cadence should have a near perfect linear relationship.

```{r echo=FALSE}
cycle_data %>% 
    ggplot() +
    geom_point(aes(cadence, speed), size = .4) +
    labs(
        title = 'Speed versus Cadence',
        subtitle = 'Data generated on a single-gear track bike',
        x = 'Cadence (RPM)',
        y = 'Speed (Metres/Second)'
    )
```

We see the linear relationship but note that there is a distribution of speeds across each cadence value. This is likely due to the difference in precision between the cadence and the speed, as cadence is measured as a integer whereas speed is a double with a single decimal point.

Finally, let's take  look at the data we'll be modelling and its relationship. We extract out the second and fourth laps from the data, then create a new *position* factor variable with appropriately named levels. We're also going to remove data where we were accelerating - i.e. the rate of change of the power between trackpoint samples was between -20 and 20 watts. I had to accelerate to move to different speed increments, but our model only relates to points of (relatively) constant speed and so these aren't valid for our model.


```{r}
cycle_data_cleaned <-
    cycle_data %>% 
    filter(
        lap %in% c(1,3),
        between(power - lag(power), -20, 20)
    ) %>%
    mutate(position = fct_recode(as_factor(lap), "Tops" = "1", "Drops" = "3"))
```

I should note that removing data to fit a model is not generally something that should be done. The difference here is that I was in control of the the data generation (not just data acquisition) process, and I have justified the rationale for the removal of the data. 

We can now view the power output versus the speed of this cleaned data.

```{r echo=FALSE}
cycle_data_cleaned %>% 
    ggplot() +
    geom_point(aes(speed, power, colour = position), size = .8) +
    labs(
        x = 'Speed (Metres/Second)',
        y = 'Power (Watts)',
        title = 'Speed versus Power',
        colour = 'Hand Position'
    )
```

We see some sort of exponential relationship between speed and power (we'll discuss that in the next section). We can also see the "blobs" of data where I have tried to keep a constant speed, and how keeping that constant speed become more difficult as I went faster. What is not instantly visible is the difference in power output versus speed for each of the different hand positions.

# Defining and Building a Model

Before we build our model in R we first have to define what the model is going to be. I'm going to be using the class drag equation:
y
$$ F_D = \frac{1}{2}\rho C_D A v^2$$
This says that the force of drag through a fluid is proportional to half of the density of the fluid (\\(\rho\\)) times the drag coefficient of my bike/body (\\(C_D\\)) time  is front on cross-sectional area ((\\(A\\)) times the square of my is my velocity (\\(v\\)). I'm going to bundle up all coefficients into a single coefficient \\(\beta\\).

$$ \text{Let } \beta = \frac{1}{2} \rho C_D A $$
$$ F_D = \beta v^2 $$
We've got force on our left-hand side, but we need power. Energy is force times distance, and power is energy over time, so we have:

$$ F_D \frac{x}{t} = \beta v^2 \frac{x}{t}$$ 
$$P_D = \beta v^2 \frac{x}{t} $$

As distance over time is simply velocity, we are left with:

$$ P_D = \beta v^3 $$ 
This is the model we're going to fit our data to. The model will give us an estimate (with some uncertainty) of the \\(\beta\\) value when I was on the tops of the handvars, and a \\(\beta\\) value when I was in the drops.

As we know the generative process for this data, we have some prior information that we should definitely include in the model: it takes zero watts to go zero metres per second. This implies that our model should go through the origin \\((0,0)\\) and we should not include an intercept. 

```{r}
cycle_data_mdl <-
    cycle_data_cleaned %>% 
    lm(power ~ 0 + position : I(speed^3), data = .) 

tidy(cycle_data_mdl)
```


```{r echo = FALSE}
crossing(
    speed = seq(4, 14, by = .1),
    position = as_factor(c('Tops', 'Drops'))
) %>%  
    mutate(
        power = predict(
            cycle_data_mdl,
            newdata = tibble(speed = speed, position = position)
        )
    ) %>%
    ggplot() +
    geom_line(aes(speed, power, colour = position)) +
    geom_point(
        aes(speed, power, colour = position),
        size = .4,
        data = cycle_data_cleaned,
    ) +
    labs(
        title = 'Speed over Power',
        subtitle = 'Regression lines overlayed with original data',
        x = 'Speed (Metres/Second)',
        y = 'Power (Watts)',
        colour = 'Hand Position'
    )
```

```{r echo=FALSE}
cycle_data_mdl %>%
    augment() %>%  
    ggplot() +
    geom_point(aes(.fitted, .std.resid)) +
    labs(
        title = 'Fitted versus Residuals',
        x = 'Fitted Value (Watts)',
        y = 'Residual (Watts)',
    )
```

```{r echo=FALSE}
cycle_data_mdl %>%
    augment() %>%  
    ggplot() +
    geom_density(aes(.std.resid))
```


```{r echo=FALSE}

tibble(
    x = seq(10, 60, .1),
    lap0 = dnorm(
        x, 
        tidy(cycle_data_mdl)[[1,'estimate']], 
        tidy(cycle_data_mdl)[[1,'std.error']]
    ),
    lap1 = dnorm(
        x, 
        tidy(cycle_data_mdl)[[2,'estimate']], 
        tidy(cycle_data_mdl)[[2,'std.error']]
    )
) %>%
    ggplot() +
    geom_area(aes(x, lap0, fill = 'lap0'), alpha = .7) +
    geom_area(aes(x, lap1, fill = 'lap1'), alpha = .7) +
    labs(
        x = 'Parameter Estimate',
        y = 'Probabilithy Density',
        title = 'Lap0 and Lap1 Parameter Uncertainty',
        fill = 'Parameter'
    )
```

